# ğŸ§  Apprentissage Continu - Guide d'Utilisation

## ğŸ“‹ Qu'est-ce que l'apprentissage continu?

Le systÃ¨me d'**apprentissage continu** (Online Learning) permet au modÃ¨le de **s'amÃ©liorer automatiquement** aprÃ¨s chaque prÃ©diction en collectant vos retours sur les coÃ»ts rÃ©els.

### ğŸ”„ Comment Ã§a marche?

```
1. Vous demandez une prÃ©diction
   â†“
2. Le modÃ¨le prÃ©dit le coÃ»t
   â†“
3. Vous fournissez le coÃ»t RÃ‰EL du voyage
   â†“
4. Le modÃ¨le apprend de son erreur
   â†“
5. Le modÃ¨le s'amÃ©liore! ğŸ“ˆ
```

---

## ğŸš€ Utilisation

### Mode 1: Interactif (RecommandÃ© pour usage rÃ©el)

```powershell
.\.venv\bin\python.exe online_learning.py
```

Choisissez **Mode 1** et suivez les instructions:

1. **Entrez les paramÃ¨tres du voyage:**
   - Distance (km)
   - Type de route (0=PavÃ©, 1=Terre, 2=CassÃ©)
   - Niveau de traffic (0=Faible, 1=Moyen, 2=Ã‰levÃ©)
   - IntensitÃ© de la pluie (0.0 Ã  1.0)
   - Nuit (0=Jour, 1=Nuit)
   - Accident (0=Non, 1=Oui)

2. **Le modÃ¨le prÃ©dit le coÃ»t**

3. **Vous entrez le coÃ»t RÃ‰EL** (aprÃ¨s avoir fait le voyage)

4. **Le modÃ¨le apprend et s'amÃ©liore!**

### Mode 2: DÃ©mo (Pour tester le systÃ¨me)

```powershell
.\.venv\bin\python.exe online_learning.py
```

Choisissez **Mode 2** pour une simulation automatique de 50 prÃ©dictions avec feedbacks.

---

## âš™ï¸ Configuration

### FrÃ©quence de mise Ã  jour

Par dÃ©faut, le modÃ¨le se met Ã  jour tous les **10 feedbacks**. Vous pouvez changer cela:

```python
predictor = OnlineLearningPredictor(
    model_path="models/PPO/100000.zip",
    update_frequency=5  # Mise Ã  jour tous les 5 feedbacks
)
```

**Recommandations:**
- `update_frequency=5` : Apprentissage rapide, mais peut Ãªtre instable
- `update_frequency=10` : **RecommandÃ©** - Bon Ã©quilibre
- `update_frequency=20` : Apprentissage lent, mais plus stable

---

## ğŸ“Š DonnÃ©es SauvegardÃ©es

Toutes les donnÃ©es sont sauvegardÃ©es dans `online_learning_data/`:

```
online_learning_data/
â”œâ”€â”€ feedback_history.json       # Historique de tous les feedbacks
â”œâ”€â”€ model_update_1.zip          # ModÃ¨le aprÃ¨s 1Ã¨re mise Ã  jour
â”œâ”€â”€ model_update_2.zip          # ModÃ¨le aprÃ¨s 2Ã¨me mise Ã  jour
â””â”€â”€ ...
```

### Format des feedbacks (JSON)

```json
{
  "timestamp": "2026-01-28T13:20:00",
  "observation": [100, 0, 1, 0.3, 0, 0],
  "predicted_cost": 13500.50,
  "actual_cost": 14200.00,
  "error": 699.50,
  "error_pct": 4.93
}
```

---

## ğŸ“ˆ Statistiques d'AmÃ©lioration

Le systÃ¨me affiche automatiquement les statistiques:

```
ğŸ“Š STATISTIQUES D'APPRENTISSAGE CONTINU
========================================

Nombre total de prÃ©dictions: 50
Nombre de mises Ã  jour du modÃ¨le: 5

Performance:
  Erreur moyenne: 1,234.56 CFA
  Erreur mÃ©diane: 987.23 CFA
  Erreur min: 123.45 CFA
  Erreur max: 3,456.78 CFA
  Erreur % moyenne: 8.5%

ğŸ“ˆ AmÃ©lioration au fil du temps:
  Erreur moyenne (10 premiers): 1,850.00 CFA
  Erreur moyenne (10 derniers): 890.00 CFA
  AmÃ©lioration: +51.9%
```

---

## ğŸ¯ Exemple d'Utilisation RÃ©elle

### ScÃ©nario: Vous Ãªtes un chauffeur de taxi

```python
# DÃ©marrer le systÃ¨me
predictor = OnlineLearningPredictor(
    model_path="models/PPO/100000.zip",
    update_frequency=10
)

# Matin - Client 1
predicted, obs = predictor.predict(
    distance=25,      # 25 km
    road_type=0,      # Route pavÃ©e
    traffic=2,        # Traffic Ã©levÃ© (heure de pointe)
    rain=0,           # Pas de pluie
    night=0,          # Jour
    accident=0        # Pas d'accident
)
print(f"Prix proposÃ©: {predicted:.0f} CFA")
# AprÃ¨s le voyage, le client a payÃ© 3500 CFA
predictor.add_feedback(obs, predicted, 3500)

# Midi - Client 2
predicted, obs = predictor.predict(
    distance=50,
    road_type=1,      # Route en terre
    traffic=0,        # Traffic faible
    rain=0.6,         # Pluie modÃ©rÃ©e
    night=0,
    accident=0
)
print(f"Prix proposÃ©: {predicted:.0f} CFA")
# Client a payÃ© 8200 CFA
predictor.add_feedback(obs, predicted, 8200)

# ... AprÃ¨s 10 courses, le modÃ¨le se met Ã  jour automatiquement!
# Les prÃ©dictions suivantes seront plus prÃ©cises!
```

---

## ğŸ”§ IntÃ©gration dans une Application

### Exemple: API REST

```python
from flask import Flask, request, jsonify
from online_learning import OnlineLearningPredictor

app = Flask(__name__)
predictor = OnlineLearningPredictor(
    model_path="models/PPO/100000.zip",
    update_frequency=10
)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.json
    predicted_cost, obs = predictor.predict(
        data['distance'],
        data['road_type'],
        data['traffic'],
        data['rain'],
        data['night'],
        data['accident']
    )
    return jsonify({
        'predicted_cost': predicted_cost,
        'observation_id': len(predictor.feedback_history)
    })

@app.route('/feedback', methods=['POST'])
def feedback():
    data = request.json
    predictor.add_feedback(
        np.array(data['observation']),
        data['predicted_cost'],
        data['actual_cost']
    )
    return jsonify({'status': 'success'})

@app.route('/stats', methods=['GET'])
def stats():
    predictor.get_statistics()
    return jsonify({'status': 'printed'})
```

---

## âš¡ Avantages de l'Apprentissage Continu

| Avantage | Description |
|----------|-------------|
| ğŸ¯ **PrÃ©cision croissante** | Plus vous l'utilisez, plus il devient prÃ©cis |
| ğŸŒ **Adaptation locale** | S'adapte aux conditions spÃ©cifiques de votre rÃ©gion |
| ğŸ“… **Ã‰volution temporelle** | S'adapte aux changements de prix au fil du temps |
| ğŸš— **Personnalisation** | Apprend de VOS donnÃ©es rÃ©elles |
| ğŸ’¾ **Historique complet** | Toutes les donnÃ©es sont sauvegardÃ©es |

---

## âš ï¸ Limitations et PrÃ©cautions

### 1. **QualitÃ© des feedbacks**
- âš ï¸ Assurez-vous que les coÃ»ts rÃ©els sont corrects
- âš ï¸ Des feedbacks erronÃ©s dÃ©gradent le modÃ¨le

### 2. **QuantitÃ© de donnÃ©es**
- âœ… Plus de feedbacks = Meilleur apprentissage
- âš ï¸ Minimum 20-30 feedbacks pour voir une amÃ©lioration

### 3. **FrÃ©quence de mise Ã  jour**
- âš ï¸ Trop frÃ©quent (< 5) = Instable
- âš ï¸ Trop rare (> 20) = Apprentissage lent

### 4. **Sauvegarde**
- âœ… Les modÃ¨les mis Ã  jour sont sauvegardÃ©s automatiquement
- âš ï¸ Sauvegardez rÃ©guliÃ¨rement `online_learning_data/`

---

## ğŸ”„ Restaurer un ModÃ¨le PrÃ©cÃ©dent

Si le modÃ¨le se dÃ©grade aprÃ¨s des mauvais feedbacks:

```python
# Charger un modÃ¨le prÃ©cÃ©dent
predictor = OnlineLearningPredictor(
    model_path="online_learning_data/model_update_3.zip"
)
```

---

## ğŸ“Š Comparer les Versions

Pour voir l'Ã©volution du modÃ¨le:

```python
# Ã‰valuer diffÃ©rentes versions
from evaluate_model import evaluate_checkpoint

# Version initiale
errors_v0 = evaluate_checkpoint("models/PPO/100000.zip")

# AprÃ¨s 1Ã¨re mise Ã  jour
errors_v1 = evaluate_checkpoint("online_learning_data/model_update_1.zip")

# AprÃ¨s 5Ã¨me mise Ã  jour
errors_v5 = evaluate_checkpoint("online_learning_data/model_update_5.zip")

print(f"Erreur initiale: {errors_v0.mean():.2f} CFA")
print(f"AprÃ¨s 1 mise Ã  jour: {errors_v1.mean():.2f} CFA")
print(f"AprÃ¨s 5 mises Ã  jour: {errors_v5.mean():.2f} CFA")
```

---

## ğŸ“ Cas d'Usage RecommandÃ©s

### âœ… Parfait pour:
- Chauffeurs de taxi collectant des donnÃ©es rÃ©elles
- Applications de covoiturage
- Entreprises de transport
- Services de livraison
- Ã‰tudes de marchÃ© sur les coÃ»ts de transport

### âŒ Moins adaptÃ© pour:
- PrÃ©dictions ponctuelles sans feedback
- Environnements oÃ¹ les coÃ»ts rÃ©els ne sont pas disponibles
- Cas oÃ¹ les feedbacks sont peu fiables

---

## ğŸš€ Workflow Complet

```
1. EntraÃ®nement initial (une fois)
   â†’ python train_agent.py
   
2. DÃ©ploiement avec apprentissage continu
   â†’ python online_learning.py
   
3. Utilisation quotidienne
   â†’ PrÃ©dictions + Feedbacks
   
4. Le modÃ¨le s'amÃ©liore automatiquement!
   â†’ Tous les 10 feedbacks
   
5. Analyse des performances
   â†’ Statistiques automatiques
```

---

## ğŸ“ Support

Pour des questions ou problÃ¨mes:
1. VÃ©rifiez que les feedbacks sont corrects
2. Consultez les statistiques rÃ©guliÃ¨rement
3. Sauvegardez vos donnÃ©es frÃ©quemment
4. Testez avec le mode dÃ©mo d'abord

---

**Le modÃ¨le s'amÃ©liore avec VOUS! Plus vous l'utilisez, plus il devient prÃ©cis! ğŸš€**
